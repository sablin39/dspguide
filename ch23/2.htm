	 

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Cameras and Eyes</title>
<link href="../new/css/default.css" rel="stylesheet" type="text/css" />

<script type='text/javascript' src='../new/js/jquery-1.5.js'></script>
<script type='text/javascript' src='../new/js/jquery.droppy.js'></script>
<link rel="stylesheet" href="../new/css/droppy.css" type="text/css" />
<script type='text/javascript' src='../new/js/jcc.js'></script>
<script>
$(function(){
	if($.browser.msie){
        if($.browser.version.substr(0,1)!="9"){
            $('#greenBox2').corner({tl:{radius:5}, tr:{radius:5}, bl:{radius:5}, br:{radius:5}, antiAlias:true });
        }
    }else{
        $('#greenBox2').corner({tl:{radius:5}, tr:{radius:5}, bl:{radius:3}, br:{radius:5}, antiAlias:true });
    }
});
</script>

<link rel="stylesheet" href="../new/css/jquery.treeview.css" />
<script src="../new/js/jquery.cookie.js" type="text/javascript"></script>
<script src="../new/js/jquery.treeview.js" type="text/javascript"></script>
<script type="text/javascript" src="../new/js/demo.js"></script>

</head>

<body>


<div id="divPage">
	<div id="wrapper" class="not-logged-in">
		
		<!-- Header -->
		
<div id="header">
			<h1>The Scientist and Engineer's Guide to<br />Digital Signal Processing<br /><span class="txtBlue txt26">By Steven W. Smith, Ph.D.</span></h1>
			<div id="menu">
				<ul id='nav' style="margin-left:10px;"><li><a href="../index.html">Home</a></li><li><a href="../pdfbook.htm" class="selected">The Book by Chapters</a></li><li class="drop"><a href="../about.htm">About the Book</a>					
					<ul>						
						<li><a href="../copyrite.htm">Copyright and permissible use</a></li>							
						<li><a href="../whatdsp.htm">What is DSP?</a></li>
						<li><a href="../eightres.htm">8 good reasons for learning DSP</a></li>
						<li><a href="../reviews.htm">Comments by reviewers</a></li>
						<li><a href="../errata.htm">Errata</a></li>			
						<li><a href="http://www.dspguide.com/ch23/download.htm">Free Software and Teaching Aids</a></li>						
						<li><a href="../editions.htm">Differences Between Editions</a></li>
					</ul>
				  </li><li><a href="../swsmith.htm">Steven W. Smith</a></li><li><a href="http://www.dsprelated.com/blogs-1/nf/Steve_Smith.php">Blog</a></li><li><a href="../contact.htm">Contact</a></li>					
				</ul>
				<script type="text/javascript">$(function() {$("#nav").droppy();});</script>
			</div>
		</div>

		
		<!-- Content -->
		
		<!-- -->		
		<div id="columnLeft">			
			
			<div class="box">
				<h2>Book Search</h2>
				<div id="search">
					<form action="http://www.dspguide.com/search.php" method="post">
						<input type="text" name="searchfor" class="txtField" />
						<input type="image" src="../new/images/btn-go.png" name="Submit" value="Submit" class="button" />
						<div class="clear"><!-- --></div>
					</form>
				</div>
			</div>
		
			
			<div class="box">
				<h2>Download this chapter in PDF format</h2>
				<b><a href="../CH23.PDF">Chapter23.pdf</a></b>
				<br />
				<img src="../new/images/adobe-reader.png" alt="" vspace="5" />
			</div>

			<div class="box">
				<h2>Table of contents</h2>
				<ul id="red" class="treeview-red">	 
					<ul style="border-top:1px solid #aeaeeb;"><li style="border-top:1px solid #aeaeeb;"><a href="../ch1.htm">1: The Breadth and Depth of DSP</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch1/1.htm">The Roots of DSP</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch1/2.htm" style="color:#b4b4e9;">Telecommunications</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch1/3.htm">Audio Processing</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch1/4.htm">Echo Location</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch1/5.htm">Image Processing</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2.htm">2: Statistics, Probability and Noise</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/1.htm">Signal and Graph Terminology</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/2.htm" style="color:#b4b4e9;">Mean and Standard Deviation</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/3.htm">Signal vs. Underlying Process</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/4.htm">The Histogram, Pmf and Pdf</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/5.htm">The Normal Distribution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/6.htm">Digital Noise Generation</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch2/7.htm">Precision and Accuracy</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3.htm">3: ADC and DAC</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/1.htm">Quantization</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/2.htm" style="color:#b4b4e9;">The Sampling Theorem</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/3.htm">Digital-to-Analog Conversion</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/4.htm">Analog Filters for Data Conversion</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/5.htm">Selecting The Antialias Filter</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/6.htm">Multirate Data Conversion</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch3/7.htm">Single Bit Data Conversion</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4.htm">4: DSP Software</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/1.htm">Computer Numbers</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/2.htm" style="color:#b4b4e9;">Fixed Point (Integers)</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/3.htm">Floating Point (Real Numbers)</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/4.htm">Number Precision</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/5.htm">Execution Speed: Program Language</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/6.htm">Execution Speed: Hardware</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch4/7.htm">Execution Speed: Programming Tips</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5.htm">5: Linear Systems</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/1.htm">Signals and Systems</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/2.htm" style="color:#b4b4e9;">Requirements for Linearity</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/3.htm">Static Linearity and Sinusoidal Fidelity</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/4.htm">Examples of Linear and Nonlinear Systems</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/5.htm">Special Properties of Linearity</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/6.htm">Superposition: the Foundation of DSP</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/7.htm">Common Decompositions</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch5/8.htm">Alternatives to Linearity</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch6.htm">6: Convolution</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch6/1.htm">The Delta Function and Impulse Response</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch6/2.htm" style="color:#b4b4e9;">Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch6/3.htm">The Input Side Algorithm</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch6/4.htm">The Output Side Algorithm</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch6/5.htm">The Sum of Weighted Inputs</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch7.htm">7: Properties of Convolution</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch7/1.htm">Common Impulse Responses</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch7/2.htm" style="color:#b4b4e9;">Mathematical Properties</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch7/3.htm">Correlation</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch7/4.htm">Speed</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8.htm">8: The Discrete Fourier Transform</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/1.htm">The Family of Fourier Transform</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/2.htm" style="color:#b4b4e9;">Notation and Format of the Real DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/3.htm">The Frequency Domain's Independent Variable</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/4.htm">DFT Basis Functions</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/5.htm">Synthesis, Calculating the Inverse DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/6.htm">Analysis, Calculating the DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/7.htm">Duality</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/8.htm">Polar Notation</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch8/9.htm">Polar Nuisances</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch9.htm">9: Applications of the DFT</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch9/1.htm">Spectral Analysis of Signals</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch9/2.htm" style="color:#b4b4e9;">Frequency Response of Systems</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch9/3.htm">Convolution via the Frequency Domain</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10.htm">10: Fourier Transform Properties</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/1.htm">Linearity of the Fourier Transform</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/2.htm" style="color:#b4b4e9;">Characteristics of the Phase</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/3.htm">Periodic Nature of the DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/4.htm">Compression and Expansion, Multirate methods</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/5.htm">Multiplying Signals (Amplitude Modulation)</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/6.htm">The Discrete Time Fourier Transform</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch10/7.htm">Parseval's Relation</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch11.htm">11: Fourier Transform Pairs</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch11/1.htm">Delta Function Pairs</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch11/2.htm" style="color:#b4b4e9;">The Sinc Function</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch11/3.htm">Other Transform Pairs</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch11/4.htm">Gibbs Effect</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch11/5.htm">Harmonics</a></li><li style="border-top:1px solid #aeaeeb;"><a href="http://www.dspguide.com/ch11/6.htm">Chirp Signals</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch12.htm">12: The Fast Fourier Transform</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch12/1.htm">Real DFT Using the Complex DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch12/2.htm" style="color:#b4b4e9;">How the FFT works</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch12/3.htm">FFT Programs</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch12/4.htm">Speed and Precision Comparisons</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch12/5.htm">Further Speed Increases</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch13.htm">13: Continuous Signal Processing</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch13/1.htm">The Delta Function</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch13/2.htm" style="color:#b4b4e9;">Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch13/3.htm">The Fourier Transform</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch13/4.htm">The Fourier Series</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14.htm">14: Introduction to Digital Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/1.htm">Filter Basics</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/2.htm" style="color:#b4b4e9;">How Information is Represented in Signals</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/3.htm">Time Domain Parameters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/4.htm">Frequency Domain Parameters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/5.htm">High-Pass, Band-Pass and Band-Reject Filters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch14/6.htm">Filter Classification</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch15.htm">15: Moving Average Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch15/1.htm">Implementation by Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch15/2.htm" style="color:#b4b4e9;">Noise Reduction vs. Step Response</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch15/3.htm">Frequency Response</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch15/4.htm">Relatives of the Moving Average Filter</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch15/5.htm">Recursive Implementation</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch16.htm">16: Windowed-Sinc Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch16/1.htm">Strategy of the Windowed-Sinc</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch16/2.htm" style="color:#b4b4e9;">Designing the Filter</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch16/3.htm">Examples of Windowed-Sinc Filters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch16/4.htm">Pushing it to the Limit</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch17.htm">17: Custom Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch17/1.htm">Arbitrary Frequency Response</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch17/2.htm" style="color:#b4b4e9;">Deconvolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch17/3.htm">Optimal Filters</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch18.htm">18: FFT Convolution</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch18/1.htm">The Overlap-Add Method</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch18/2.htm" style="color:#b4b4e9;">FFT Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch18/3.htm">Speed Improvements</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch19.htm">19: Recursive Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch19/1.htm">The Recursive Method</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch19/2.htm" style="color:#b4b4e9;">Single Pole Recursive Filters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch19/3.htm">Narrow-band Filters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch19/4.htm">Phase Response</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch19/5.htm">Using Integers</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch20.htm">20: Chebyshev Filters</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch20/1.htm">The Chebyshev and Butterworth Responses</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch20/2.htm" style="color:#b4b4e9;">Designing the Filter</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch20/3.htm">Step Response Overshoot</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch20/4.htm">Stability</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch21.htm">21: Filter Comparison</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch21/1.htm">Match #1: Analog vs. Digital Filters</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch21/2.htm" style="color:#b4b4e9;">Match #2: Windowed-Sinc vs. Chebyshev</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch21/3.htm">Match #3: Moving Average vs. Single Pole</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22.htm">22: Audio Processing</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/1.htm">Human Hearing</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/2.htm" style="color:#b4b4e9;">Timbre</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/3.htm">Sound Quality vs. Data Rate</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/4.htm">High Fidelity Audio</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/5.htm">Companding</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/6.htm">Speech Synthesis and Recognition</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch22/7.htm">Nonlinear Audio Processing</a></li></ul></li><li class="open" style="border-top:1px solid #aeaeeb;"><a href="../ch23.htm" style="color:#b4b4e9;">23: Image Formation & Display</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="1.htm">Digital Image Structure</a></li><li style="border-top:1px solid #aeaeeb;"><a href="2.htm" style="color:#b4b4e9;">Cameras and Eyes</a></li><li style="border-top:1px solid #aeaeeb;"><a href="3.htm">Television Video Signals</a></li><li style="border-top:1px solid #aeaeeb;"><a href="4.htm">Other Image Acquisition and Display</a></li><li style="border-top:1px solid #aeaeeb;"><a href="5.htm">Brightness and Contrast Adjustments</a></li><li style="border-top:1px solid #aeaeeb;"><a href="6.htm">Grayscale Transforms</a></li><li style="border-top:1px solid #aeaeeb;"><a href="7.htm">Warping</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24.htm">24: Linear Image Processing</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/1.htm">Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/2.htm" style="color:#b4b4e9;">3x3 Edge Modification</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/3.htm">Convolution by Separability</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/4.htm">Example of a Large PSF: Illumination Flattening</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/5.htm">Fourier Image Analysis</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/6.htm">FFT Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch24/7.htm">A Closer Look at Image Convolution</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch25.htm">25: Special Imaging Techniques</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch25/1.htm">Spatial Resolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch25/2.htm" style="color:#b4b4e9;">Sample Spacing and Sampling Aperture</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch25/3.htm">Signal-to-Noise Ratio</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch25/4.htm">Morphological Image Processing</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch25/5.htm">Computed Tomography</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26.htm">26: Neural Networks (and more!)</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/1.htm">Target Detection</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/2.htm" style="color:#b4b4e9;">Neural Network Architecture</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/3.htm">Why Does it Work?</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/4.htm">Training the Neural Network</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/5.htm">Evaluating the Results</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch26/6.htm">Recursive Filter Design</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27.htm">27: Data Compression</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/1.htm">Data Compression Strategies</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/2.htm" style="color:#b4b4e9;">Run-Length Encoding</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/3.htm">Huffman Encoding</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/4.htm">Delta Encoding</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/5.htm">LZW Compression</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/6.htm">JPEG (Transform Compression)</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch27/7.htm">MPEG</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28.htm">28: Digital Signal Processors</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/1.htm">How DSPs are Different from Other Microprocessors</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/2.htm" style="color:#b4b4e9;">Circular Buffering</a></li><li style="border-top:1px solid #aeaeeb;"><a href="http://www.dspguide.com/ch28/3.htm">Architecture of the Digital Signal Processor</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/4.htm">Fixed versus Floating Point</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/5.htm">C versus Assembly</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/6.htm">How Fast are DSPs?</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch28/7.htm">The Digital Signal Processor Market</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29.htm">29: Getting Started with DSPs</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="http://www.dspguide.com/ch29/1.htm">The ADSP-2106x family</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29/2.htm" style="color:#b4b4e9;">The SHARC EZ-KIT Lite</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29/3.htm">Design Example: An FIR Audio Filter</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29/4.htm">Analog Measurements on a DSP System</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29/5.htm">Another Look at Fixed versus Floating Point</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch29/6.htm">Advanced Software Tools</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30.htm">30: Complex Numbers</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/1.htm">The Complex Number System</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/2.htm" style="color:#b4b4e9;">Polar Notation</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/3.htm">Using Complex Numbers by Substitution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/4.htm">Complex Representation of Sinusoids</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/5.htm">Complex Representation of Systems</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch30/6.htm">Electrical Circuit Analysis</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch31.htm">31: The Complex Fourier Transform</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch31/1.htm">The Real DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch31/2.htm" style="color:#b4b4e9;">Mathematical Equivalence</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch31/3.htm">The Complex DFT</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch31/4.htm">The Family of Fourier Transforms</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch31/5.htm">Why the Complex Fourier Transform is Used</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch32.htm">32: The Laplace Transform</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch32/1.htm">The Nature of the s-Domain</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch32/2.htm" style="color:#b4b4e9;">Strategy of the Laplace Transform</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch32/3.htm">Analysis of Electric Circuits</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch32/4.htm">The Importance of Poles and Zeros</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch32/5.htm">Filter Design in the s-Domain</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33.htm">33: The z-Transform</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/1.htm">The Nature of the z-Domain</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/2.htm" style="color:#b4b4e9;">Analysis of Recursive Systems</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/3.htm">Cascade and Parallel Stages</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/4.htm">Spectral Inversion</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/5.htm">Gain Changes</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/6.htm">Chebyshev-Butterworth Filter Design</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch33/7.htm">The Best and Worst of DSP</a></li></ul></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34.htm">34: Explaining Benford's Law</a><ul><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/1.htm">Frank Benford's Discovery</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/2.htm" style="color:#b4b4e9;">Homomorphic Processing</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/3.htm">The Ones Scaling Test</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/4.htm">Writing Benford's Law as a Convolution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/5.htm">Solving in the Frequency Domain</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/6.htm">Solving Mystery #1</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/7.htm">Solving Mystery #2</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/8.htm">More on Following Benford's law</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/9.htm">Analysis of the Log-Normal Distribution</a></li><li style="border-top:1px solid #aeaeeb;"><a href="../ch34/10.htm">The Power of Signal Processing</a></li></ul></li>
					</ul>
				</ul>			
			</div>

			<div class="box">
				<h2>How to order your own hardcover copy</h2>
				Wouldn't you rather have a bound book instead of 640 loose pages?<br />
				Your laser printer will thank you!<br />
				<b>Order from <a href="http://www.amazon.com/Scientist-Engineers-Digital-Signal-Processing/dp/0966017633/ref=pd_bxgy_b_img_a">Amazon.com</a>.</b>
			</div>

		
			
		</div>	

		<!-- -->		
		<div id="columnRight">	
		
			<div id="adbox">
				
			
			</div>	 
			
<div class="breadcrumbs"><a href="../ch23.htm">Chapter 23 - Image Formation & Display</a> / Cameras and Eyes</div><h2>Chapter 23: Image Formation & Display</h2><div class="subTitle">Cameras and Eyes</div><p><div style="text-align: justify"><p>The structure and operation of the eye is very similar to an electronic camera,
and it is natural to discuss them together.  Both are based on two major
components: a lens assembly, and an imaging sensor.  The lens assembly
captures a portion of the light emanating from an object, and focus it onto the
imaging sensor.  The imaging sensor then transforms the pattern of light into a
video signal, either electronic or neural.</p>

<p>Figure 23-2 shows the operation of the lens.  In this example, the image of an
ice skater is focused onto a screen.  The term <i>focus</i> means there is a one-to-one
match of every point on the ice skater with a corresponding point on the screen. 
For example, consider a 1 mm ? 1 mm region on the tip of the toe.   In bright
light, there are roughly 100 trillion photons of light striking this one square
millimeter area each second.  Depending on the characteristics of the surface,
between 1 and 99 percent of these incident light photons will be reflected in
random directions.  Only a small portion of these reflected photons will pass
through the lens.  For example, only about one-millionth of the reflected light
will pass through a one centimeter diameter lens located 3 meters from the
object.</p>

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_2.gif" border="0" alt=""></img></div>

<p>Refraction in the lens changes the direction of the individual photons,
depending on the location and angle they strike the glass/air interface. These
direction changes cause light expanding from a single point to return to a single
point on the projection screen.   All of the photons that reflect from the toe <i>and</i>
pass through the lens are brought back together at the "toe" in the projected
image.  In a similar way, a portion of the light coming from <i>any</i> point on the
object will pass through the lens, and be focused to a corresponding point in the
projected image.</p>

<p>Figures 23-3 and 23-4 illustrate the major structures in an electronic camera and
the human eye, respectively.  Both are light tight enclosures with a lens
mounted at one end and an image sensor at the other.   The camera is filled with
air, while the eye is filled with a transparent liquid.  Each lens system has two
adjustable parameters: <span style="font-weight: bold">focus</span> and <span style="font-weight: bold">iris diameter</span>.</p>

<p>If the lens is not properly focused, each point on the object will project to a
circular region on the imaging sensor, causing the image to be blurry.  In the
camera, focusing is achieved by physically moving the lens toward or away
from the imaging sensor.  In comparison, the eye contains two lenses, a bulge
on the front of the eyeball called the cornea, and an adjustable lens inside the
eye.  The cornea does most of the light refraction, but is fixed in shape and
location.  Adjustment to the focusing is accomplished by the inner lens, a
flexible structure that can be deformed by the action of the <i>ciliary muscles</i>.  As
these muscles contract, the lens flattens to bring the object into a sharp focus.</p>

<p>In both systems, the <i>iris</i> is used to control how much of the lens is exposed to
light, and therefore the brightness of the image projected onto the imaging
sensor.  The iris of the eye is formed from opaque muscle tissue that can be
contracted to make the <i>pupil</i> (the light opening) larger.  The iris in a camera is
a mechanical assembly that performs the same function. </p>

<p>The parameters in optical systems interact in many unexpected ways.  For
example, consider how the amount of available light and the sensitivity of the
light sensor affects the <i>sharpness</i> of the acquired image.  This is because the <i>iris
diameter</i> and the <i>exposure time</i> are adjusted to transfer the proper amount of
light from the scene being viewed to the image sensor.  If more than enough
light is available, the diameter of the iris can be reduced, resulting in a greater
<i>depth-of-field</i> (the range of distance from the camera where an object remains
in focus).  A greater depth-of-field provides a sharper image when objects are
at various distances.  In addition, an abundance of light allows the exposure
time to be reduced, resulting in less blur from camera shaking and object
motion.  Optical systems are full of these kinds of trade-offs. </p>

<p>An adjustable iris is necessary in both the camera and eye because the range of
light intensities in the environment is much larger than can be directly handled
by the light sensors.   For example, the difference in light intensities between
sunlight and moonlight is about one-million.  Adding to this that reflectance can 
vary between 1% and 99%, results in a light intensity range of almost <i>one-hundred million</i>.</p>

<p>The <span style="font-weight: bold">dynamic range</span> of an electronic camera is typically 300 to 1000, defined as the largest signal that can be measured, divided by the inherent noise of the
device.   Put another way,  the maximum signal produced is 1 volt, and the rms
noise in the dark is about 1 millivolt.  Typical camera lenses have an iris that
change the area of the light opening by a factor of about 300.  This results in a
typical electronic camera having a dynamic range of a few hundred thousand. 
Clearly, the same camera and lens assembly used in bright sunlight will be
useless on a dark night.</p>

<p>In comparison, the eye operates over a dynamic range that nearly covers the
large environmental variations.   Surprisingly, the iris is not the main way that
this tremendous dynamic range is achieved.  From dark to light, the area of the
pupil only changes by a factor of about 20.  The light detecting nerve cells
gradually adjust their sensitivity to handle the remaining dynamic range.  For
instance, it takes several minutes for your eyes to adjust to the low light after
walking into a dark movie theater. </p>

<p>One way that DSP can improve images is by reducing the dynamic range an
observer is required to view.  That is, we do not want very light and very dark
areas in the same image.   A reflection image is formed from <i>two</i> image signals: 
the two-dimensional pattern of how the scene is <i>illuminated</i>, multiplied by the
two-dimensional pattern of <i>reflectance</i> in the scene.  The pattern of reflectance
has a dynamic range of less than 100, because all ordinary materials reflect
between 1% and 99% of the incident light.  This is where most of the <i>image
information</i> is contained, such as where objects are located in the scene and
what their surface characteristics are.  In comparison, the illumination signal
depends on the light sources around the objects, but not on the objects
themselves.  The illumination signal can have a dynamic range of millions,
although 10 to 100 is more typical within a single image.  The illumination
signal carries little interesting information,</p>

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_3.gif" border="0" alt=""></img></div>

<p>but can degrade the final image by increasing its dynamic range.  DSP can
improve this situation by suppressing the illumination signal, allowing the
reflectance signal to dominate the image. The next chapter presents an approach
for implementing this algorithm.  </p>

<p>The light sensitive surface that covers the rear of the eye is called the <span style="font-weight: bold">retina</span>. As shown in Fig. 23-5, the retina can be divided into three main layers of
specialized nerve cells: one for converting light into neural signals, one for
image processing, and one for transferring information to the optic nerve
leading to the brain.  In nearly all animals, these layers are seemingly <i>backward.</i> 
That is, the light sensitive cells are in last layer, requiring light to pass through
the other layers before being detected.</p>

<p>There are two types of cells that detect light: <span style="font-weight: bold">rods</span> and <span style="font-weight: bold">cones</span>, named for their
physical appearance under the microscope.  The rods are specialized in
operating with very little light, such as under the nighttime sky.  Vision appears
very <i>noisy </i>in near darkness, that is, the image appears to be filled with a
continually changing grainy pattern.  This results from the image signal being
very weak, and is not a limitation of the eye.  There is so little light entering the
eye, the random detection of individual photons can be seen.  This is called
<i>statistical noise</i>, and is encountered in all low-light imaging, such as military
night vision systems.  Chapter 25 will revisit this topic.  Since rods cannot
detect color, low-light vision is in black and white.</p>

<p>The cone receptors are specialized in distinguishing color, but can only operate
when a reasonable amount of light is present.  There are three types of cones in
the eye:  red sensitive, green sensitive, and blue sensitive.  This results from
their containing different  <i>photopigments</i>, chemicals  that absorbs different
wavelengths (colors) of light.   Figure 23-6 shows the wavelengths of light that
trigger each of these three receptors.  This is called <span style="font-weight: bold">RGB encoding</span>, and is how
color information leaves the eye through the optic nerve.  The human perception
of color is made more complicated by neural processing in the lower levels of
the brain.  The RGB encoding is converted into another encoding scheme,
where colors are classified as: red <i>or</i> green, blue <i>or</i> yellow, and light <i>or</i> dark.</p>

<p>RGB encoding is an important limitation of human vision; the wavelengths that
exist in the environment are lumped into only three broad categories.  In
comparison, specialized cameras can separate the optical spectrum into
hundreds or thousands of individual colors.  For example, these might be used
to classify cells as cancerous or healthy, understand the physics of a distant star,
or see camouflaged soldiers hiding in a forest.  Why is the eye so limited in
detecting color?  Apparently, all humans need for survival is to find a <i>red</i> apple,
among the <i>green</i> leaves, silhouetted against the <i>blue</i> sky.</p>

<p>Rods and cones are roughly 3 &#956;m wide, and are closely packed over the entire
3 cm by 3 cm surface of the retina.  This results in the retina being composed of
an array of roughly 10,000 ? 10,000 = 100 million receptors.  In comparison,
the optic nerve only has about one-million nerve fibers that connect to these
cells.   On the average, each optic nerve fiber is connected to roughly 100 light
receptors through the connecting layer.  In addition to consolidating
information, the connecting layer enhances the image by sharpening edges and
suppressing the illumination component of the scene.  This biological image
processing will be discussed in the next chapter. </p>

<p>Directly in the center of the retina is a small region called the <span style="font-weight: bold">fovea</span> (Latin for <i>pit</i>), which is used for high resolution vision (see Fig. 23-4).  The fovea is
different from the remainder of the retina in several respects.   First, the optic
nerve and interconnecting layers are pushed to the side of the fovea, allowing
the receptors to be more directly exposed to the incoming light.  This results in
the fovea appearing as a small depression in the retina.  Second, only cones are
located in the fovea, and they are more tightly packed that in the remainder of
the retina.  This absence of rods in the fovea explains why night vision is often
better when looking to the <i>side</i> of an object, rather than directly at it.  Third,
each optic nerve fiber is influenced by only a few cones, proving good
localization ability.  The fovea is surprisingly small.  At normal reading
distance, the fovea only sees about a 1 mm diameter area, less than the size of
a single letter!   The resolution is equivalent to about a 20?20 grid of pixels
within this region.</p>

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_5.gif" border="0" alt=""></img></div>

<p>Human vision overcomes the small size of the fovea by jerky eye movements
called <span style="font-weight: bold">saccades</span>.  These abrupt motions allow the high resolution fovea to
rapidly scan the field of vision for pertinent information.  In addition, saccades
present the rods and cones with a continually changing pattern of light.  This is
important because of the natural ability of the retina to adapt to changing levels
of light intensity.  In fact, if the eye is forced to remain fixed on the same scene,
detail and color begin to fade in a few seconds.</p>

<p>The most common image sensor used in electronic cameras is the <span style="font-weight: bold">charge
coupled device</span> (<span style="font-weight: bold">CCD</span>).  The CCD is an integrated circuit that replaced most vacuum tube cameras in the 1980s, just as transistors replaced vacuum tube
amplifiers twenty years before.  The heart of the CCD is a thin wafer of</p>

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_6.gif" border="0" alt=""></img></div>

<p>silicon, typically about 1 cm square.  As shown by the cross-sectional view in
Fig. 23-7, the backside is coated with a thin layer of metal connected to ground
potential.  The topside is covered with a thin electrical insulator, and a repetitive
pattern of electrodes.   The most common type of CCD is the <span style="font-weight: bold">three phase
readout</span>, where every third electrode is connected together.  The silicon used is
called <i>p-type</i>,  meaning it has an excess of positive charge carriers called <i>holes</i>. 
For this discussion, a hole can be thought of as a positively charged particle that
is free to move around in the silicon.  Holes are represented in this figure by the
"+" symbol. </p>

<p>In (a), +10 volts is applied to one of the three phases, while the other two are
held at 0 volts.  This causes the holes to move away from every third electrode,
since positive charges are repelled by a positive voltage.  This forms a region
under these electrodes called a <span style="font-weight: bold">well</span>, a shortened version of the physics term:
<i>potential well</i>.</p>

<p>Each well in the CCD is a very efficient light sensor.  As shown in (b), a single
photon of light striking the silicon converts its energy into the formation of two
charged particles, one electron, and one hole.  The hole moves away, leaving
the electron stuck in the well, held by the positive voltage on the electrode. 
Electrons in this illustration are represented by the "-" symbol.   During the
<span style="font-weight: bold">integration period</span>, the pattern of light striking the CCD is transferred into a
pattern of charge within the CCD wells.  Dimmer light sources require longer
integration periods.  For example, the integration period for standard television
is 1/60th of a second, while astrophotography can accumulate light for many
hours.  </p>

<p>Readout of the electronic image is quite clever; the accumulated electrons in
each well are <i>pushed</i> to the output amplifier.  As shown in (c), a positive voltage
is placed on <i>two</i> of the phase lines.  This results in each well expanding to the
right.  As shown in (d), the next step is to remove the voltage from the first
phase, causing the original wells to collapse.  This leaves the accumulated
electrons in one well to the right of where they started.  By repeating this
pulsing sequence among the three phase lines, the accumulated electrons are
pushed to the right until they reach a <span style="font-weight: bold">charge sensitive amplifier</span>.  This is a fancy name for a capacitor followed by a unity gain buffer.  As the electrons are
pushed from the last well, they flow onto the capacitor where they produce a
voltage.  To achieve high sensitivity, the capacitors are made extremely small,
usually less than 1 &#961;F.  This capacitor and amplifier are an integral part of the
CCD, and are made on the same piece of silicon.  The signal leaving the CCD
is a sequence of voltage levels proportional to the amount of light that has fallen
on sequential wells.</p>

<p>Figure 23-8 shows how the two-dimensional image is read from the CCD.  After
the integration period, the charge accumulated in each well is moved up the
column, one row at a time.  For example, all the wells in row 15 are first moved
into row 14, then row 13, then row 12, etc.  Each time the rows are moved up,
all the wells in row number 1 are transferred into the <span style="font-weight: bold">horizontal register</span>.  This is a group of specialized CCD wells that rapidly move the charge in a horizontal
direction to the charge sensitive amplifier.</p>

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_7.gif" border="0" alt=""></img></div> 

<div style="text-align: center; margin: 20px;"><img src="../graphics/F_23_8.gif" border="0" alt=""></img></div>

<p>Notice that this architecture converts a two-dimensional array into a serial data
stream in a particular sequence.  The first pixel to be read is at the top-left
corner of the image.  The readout then proceeds from left-to-right on the first
line, and then continues from left-to-right on subsequent lines.  This is called
<span style="font-weight: bold">row major order</span>, and is almost always followed when a two-dimensional array
(image) is converted to sequential data.</p></div></p>Next Section: <a href="3.htm">Television Video Signals</a>			

		</div>
		<div class="clear"><!-- --></div>
		

	</div>
</div>

<!-- Footer -->

<div id="footer">
	<a href="../index.html">Home</a> | <a href="../pdfbook.htm">The Book by Chapters</a> | <a href="../about.htm">About the Book</a> | <a href="../swsmith.htm">Steven W. Smith</a> | <a href="http://www.dsprelated.com/blogs-1/nf/Steve_Smith.php">Blog</a> | <a href="../contact.htm">Contact</a>
	<br />
	Copyright Â© 1997-2011 by California Technical Publishing
</div>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-1774944-11");
pageTracker._trackPageview();
} catch(err) {}</script>

</body>
</html>
